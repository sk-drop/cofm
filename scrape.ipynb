{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('music': venv)"
  },
  "interpreter": {
   "hash": "085e3d6120092fa0b16046929bf486bf837a4b5be63a2b5b002f6e5713fed73a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url to start from \n",
    "url = \"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1970?oldformat=true\"\n",
    "# search pattern to find year and correct table\n",
    "pattern = re.compile(\"\\d{4}\")\n",
    "\n",
    "\n",
    "# increasing the year within the url we want to access \n",
    "def linkup(url):\n",
    "    oldYear = pattern.search(url).group(0)\n",
    "    newYear = int(oldYear) + 1\n",
    "    url = url.replace(oldYear, str(newYear))\n",
    "\n",
    "    return url\n",
    "\n",
    "# clean entries from unnecessary characters\n",
    "def clean(entry):\n",
    "    entry = entry.replace('\"', '')\n",
    "    return entry \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scraper which visits every wiki article and save the table into a csv via pandas\n",
    "def scraper(url):\n",
    "    allSongs = pd.DataFrame()\n",
    "    # loop through every year 1970-2020\n",
    "    for i in range(0,51,1):\n",
    "        df = pd.read_html(url,header=[0],index_col=0,match=\"No.\")[0]\n",
    "        df['Title'] = df['Title'].apply(clean)\n",
    "        df.to_csv(\"./data/{}.csv\".format(pattern.search(url).group(0)))\n",
    "        allSongs = allSongs.append(df)\n",
    "        url = linkup(url)\n",
    "    \n",
    "    return allSongs\n",
    "\n",
    "allSongs = scraper(url)\n",
    "allSongs.to_csv(\"./data/allSongs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}